{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqlNTHwfN935",
        "outputId": "283c08f4-b4f8-49c0-d57f-3320e7289331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Requirement already satisfied: torch==1.11.0+cu113 in /usr/local/lib/python3.10/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchdata==0.3.0 in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torchtext==0.12.0 in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.3.0) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.3.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.12.0) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.12.0) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.3.0) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.3.0) (2024.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch==1.11.0+cu113 torchdata==0.3.0 torchtext==0.12.0 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "%pip install spacy tqdm\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1EQrjhkN937",
        "outputId": "cf01b4dd-1107-4a30-c90b-b7971bb687cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.11.0+cu113\n",
            "torchtext Version:  0.12.0\n",
            "Using GPU.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "\n",
        "SEED = 1234\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"torchtext Version: \", torchtext.__version__)\n",
        "print(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nWdnj7WP2FD",
        "outputId": "978e325b-228c-4e28-8bfe-ddb509fbec0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT1Gag0aN938",
        "outputId": "87da767a-fa13-4c47-862e-b8d91b55b683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q5HsqGU4N938"
      },
      "outputs": [],
      "source": [
        "train = dataset[\"train\"]\n",
        "valid = dataset[\"validation\"]\n",
        "test = dataset[\"test\"]\n",
        "\n",
        "\n",
        "train_tokens = train[\"tokens\"]\n",
        "train_labels = train[\"ner_tags\"]\n",
        "valid_tokens = valid[\"tokens\"]\n",
        "valid_labels = valid[\"ner_tags\"]\n",
        "test_tokens = test[\"tokens\"]\n",
        "test_labels = test[\"ner_tags\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FjTuqlkN939",
        "outputId": "5077e8c8-a69d-4388-f3c1-fdea5f0513d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['For', 'this', 'purpose', 'the', 'Gothenburg', 'Young', 'Persons', 'Empowerment', 'Scale', '(', 'GYPES', ')', 'was', 'developed', '.'], ['The', 'following', 'physiological', 'traits', 'were', 'measured', ':', 'stomatal', 'conductance', '(', 'gs', ',', 'mol', 'H2O', 'm-2', 's-1', ')', ',', 'transpiration', 'rate', '(', 'E', ',', 'mmol', 'H2O', 'm-2', 's-1', ')', ',', 'net', 'photosynthetic', 'rate', '(', 'PN', ',', 'μmol', 'm-2', 's-1', ')', 'and', 'intercellular', 'CO2', 'concentration', 'CO2', '(', 'Ci', ',', 'μmol', 'm-2', 's-1', ')', '.']]\n",
            "[['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O'], ['B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'B-AC', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O']]\n",
            "1072\n",
            "1072\n"
          ]
        }
      ],
      "source": [
        "print(train_tokens[:2])\n",
        "print(train_labels[:2])\n",
        "print(len(train_tokens))\n",
        "print(len(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SWGWPSUfN939"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "class SpacyTokenizer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
        "\n",
        "    def forward(self, input):\n",
        "        if isinstance(input, list):\n",
        "            tokens = []\n",
        "            for text in input:\n",
        "                tokens.append(self.tokenizer(text))\n",
        "            return tokens\n",
        "        elif isinstance(input, str):\n",
        "            return self.tokenizer(input)\n",
        "        raise ValueError(f\"Type {type(input)} is not supported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I9LqUP-YN93-"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, vocab\n",
        "\n",
        "from collections import OrderedDict\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "tokenizer = SpacyTokenizer()\n",
        "\n",
        "def _process_texts_for_vocab(data):\n",
        "\tfor line in data:\n",
        "\t\tyield tokenizer(\" \".join(line))\n",
        "\n",
        "\n",
        "\n",
        "text_vocab = build_vocab_from_iterator(_process_texts_for_vocab(train_tokens), specials=('<unk>', '<pad>'), max_tokens=MAX_VOCAB_SIZE)\n",
        "label_vocab = vocab(OrderedDict([(\"B-O\", 1), (\"B-AC\", 2), (\"B-LF\", 3), (\"I-LF\", 4)]))\n",
        "\n",
        "text_vocab.set_default_index(text_vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV2NSljWN93-",
        "outputId": "813ff8f7-df0d-40b6-a944-2690bcbb2561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I-LF': 3, 'B-LF': 2, 'B-AC': 1, 'B-O': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "label_vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y4-lkNeN93-",
        "outputId": "382643c6-8cb9-4836-edf1-b702fb822152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in text vocabulary: 9121\n",
            "Unique tokens in label vocabulary: 4\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unique tokens in text vocabulary: {len(text_vocab)}\")\n",
        "print(f\"Unique tokens in label vocabulary: {len(label_vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftaHHXcUN93-",
        "outputId": "c4bb0a51-d6d1-45e7-dcd9-9aa082686be9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[';',\n",
              " 'in',\n",
              " 'to',\n",
              " ']',\n",
              " '[',\n",
              " 'a',\n",
              " 'with',\n",
              " 'for',\n",
              " 'were',\n",
              " 'was',\n",
              " ':',\n",
              " 'by',\n",
              " 'is',\n",
              " '%',\n",
              " 'that',\n",
              " 'as',\n",
              " 'The',\n",
              " 'from',\n",
              " '1',\n",
              " 'are']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "text_vocab.get_itos()[10:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "14l7SwXwN93-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.transforms import ToTensor, VocabTransform, Truncate\n",
        "import torchtext.transforms as T\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_dataset(tokens, labels):\n",
        "  flattened_tokens = [item for sublist in tokens for item in sublist]\n",
        "  flattened_labels = [item for sublist in labels for item in sublist]\n",
        "  return flattened_tokens, flattened_labels\n",
        ""
      ],
      "metadata": {
        "id": "HpB9mj2pRmpe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens, train_labels = transform_dataset(train_tokens, train_labels)\n",
        "valid_tokens, valid_labels = transform_dataset(valid_tokens, valid_labels)\n",
        "test_tokens, test_labels = transform_dataset(test_tokens, test_labels)\n",
        "\n",
        "len(train_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbjt15spRzk2",
        "outputId": "903bd900-db18-4512-adcb-6201a4505394"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYJ3K46rN93_",
        "outputId": "c78a588a-f89d-4d2a-8d6f-5e108c1809cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "class ToLengths(torch.nn.Module):\n",
        "    def forward(self, input):\n",
        "        if isinstance(input[0], list):\n",
        "            lengths = []\n",
        "            for text in input:\n",
        "                lengths.append(len(text))\n",
        "            return lengths\n",
        "        elif isinstance(input, list):\n",
        "            return len(input)\n",
        "        elif isinstance(input, str):\n",
        "          return len(input)\n",
        "        raise ValueError(f\"Type {type(input)} is not supported.\")\n",
        "\n",
        "lengths_transform = T.Sequential(\n",
        "    SpacyTokenizer(),\n",
        "    ToLengths(),\n",
        "    T.ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WrGwz-14N93_"
      },
      "outputs": [],
      "source": [
        "import torchtext.transforms as T\n",
        "\n",
        "text_transform = T.Sequential(\n",
        "    #SpacyTokenizer(),  # Tokenize\n",
        "    T.VocabTransform(text_vocab),  # Conver to vocab IDs\n",
        "    T.ToTensor(padding_value=text_vocab[\"<pad>\"]),  # Convert to tensor and pad\n",
        ")\n",
        "\n",
        "label_transform = T.Sequential(\n",
        "    T.LabelToIndex(label_vocab.get_itos()),  # Convert to integer\n",
        "    T.ToTensor(),  # Convert to tensor\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_label, sample_text = train_labels[:10], train_tokens[:10]\n",
        "\n",
        "print(f\"Text before any processing: {sample_text}\")\n",
        "print(f\"Label before any processing: {sample_label}\\n\")\n",
        "\n",
        "#Text processing pipeline\n",
        "\n",
        "vocab_transform = T.VocabTransform(text_vocab)\n",
        "sample_text = vocab_transform(sample_text)\n",
        "\n",
        "print(f\"Text after Vocab Transform: {sample_text}\\n\")\n",
        "\n",
        "tensor_transform = T.ToTensor(padding_value=text_vocab[\"<pad>\"])\n",
        "sample_text = tensor_transform(sample_text)\n",
        "print(f\"Text after Tensor Transform: {sample_text}\\n\")\n",
        "print(type(sample_text))\n",
        "# Label Processing Pipeline\n",
        "print(f\"Label after label transform: {label_transform(sample_label)}\\n\")\n",
        "\n",
        "# # Length Processing Pipeline\n",
        "print(f\"Text after length transform: {lengths_transform(train_tokens[:10])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7piUy-BYMoE",
        "outputId": "1e9fc5aa-9635-4720-cdb0-6840ba5696f8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before any processing: ['For', 'this', 'purpose', 'the', 'Gothenburg', 'Young', 'Persons', 'Empowerment', 'Scale', '(']\n",
            "Label before any processing: ['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O']\n",
            "\n",
            "Text after Vocab Transform: [254, 60, 8411, 5, 4886, 6323, 5689, 4680, 1621, 3]\n",
            "\n",
            "Text after Tensor Transform: tensor([ 254,   60, 8411,    5, 4886, 6323, 5689, 4680, 1621,    3])\n",
            "\n",
            "<class 'torch.Tensor'>\n",
            "Label after label transform: tensor([0, 0, 0, 0, 2, 3, 3, 3, 3, 0])\n",
            "\n",
            "Text after length transform: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unsqueezed= sample_text.unsqueeze(1)\n",
        "unsqueezed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qspE1rpBfIHK",
        "outputId": "f3f46004-bd65-4b5f-ee8f-20c0442dd7ff"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 254],\n",
              "        [  60],\n",
              "        [8411],\n",
              "        [   5],\n",
              "        [4886],\n",
              "        [6323],\n",
              "        [5689],\n",
              "        [4680],\n",
              "        [1621],\n",
              "        [   3]])"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbpwPC-EN93_",
        "outputId": "82354aac-8a16-4273-dd52-4aee93272381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF']\n",
            "['For', 'this']\n",
            "[254, 60]\n",
            "tensor([254,  60])\n"
          ]
        }
      ],
      "source": [
        "sample_labels, sample_texts = train_labels[:6], train_tokens[:2]\n",
        "print(sample_labels)\n",
        "print(sample_texts)\n",
        "#vocab convert the texts\n",
        "vocab_transform = T.VocabTransform(text_vocab)\n",
        "sample_text = vocab_transform(sample_texts)\n",
        "print(sample_text)\n",
        "processed_sample_texts = text_transform(list(sample_texts))\n",
        "print(processed_sample_texts)\n",
        "\n",
        "# diff = abs(lengths[0] - lengths[1]) + 5|\n",
        "\n",
        "# print(f\"Padding vocabulary index: {text_vocab['<pad>']}\")\n",
        "\n",
        "# print(\"Respective text lengths after tokenization: \", lengths)\n",
        "# print(\"Tensor shape after text processing: \", processed_sample_texts.shape)\n",
        "# print(f\"Last {diff} characters of text 0 after processing:\\n\", processed_sample_texts[0][-diff:])\n",
        "# print(f\"Last {diff} characters of text 1 after processing:\\n\", processed_sample_texts[1][-diff:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "puWh_lInN93_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def collate_batch(batch):\n",
        "    labels, texts = zip(*batch)\n",
        "    lengths = torch.ones(BATCH_SIZE)\n",
        "    texts = text_transform(list(texts))\n",
        "    labels = label_transform(list(labels))\n",
        "    labels = labels.long()\n",
        "    texts = texts.unsqueeze(1)\n",
        "\n",
        "    return labels.float().to(DEVICE), texts.to(DEVICE), lengths.cpu()\n",
        "\n",
        "def _get_dataloader(data):\n",
        "    return DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last = True)\n",
        "\n",
        "train_data = list(zip(train_labels, train_tokens))\n",
        "valid_data = list(zip(valid_labels, valid_tokens))\n",
        "test_data = list(zip(test_labels, test_tokens))\n",
        "\n",
        "train_dataloader = _get_dataloader(train_data)\n",
        "valid_dataloader = _get_dataloader(valid_data)\n",
        "test_dataloader = _get_dataloader(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    labels, texts, lengths = batch\n",
        "    print(texts.shape)  # Should be (BATCH_SIZE, sequence_length) or similar\n",
        "    print(labels.shape)  # Should be (BATCH_SIZE, )\n",
        "    break  # Remove this to loop through all batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFXdzplVZth9",
        "outputId": "b4a7ef1b-c403-4152-c1a5-1b2f6505c0bf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wgvmjAEN94A",
        "outputId": "efd1798a-4de9-4436-e220-acfd7740bfec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 2, 3, 3, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([ 254,   60, 8411,    5, 4886, 6323, 5689, 4680, 1621,    3, 4855,    4,\n",
            "          19,  312,    6,   26,  235, 3255, 8903,   18])\n"
          ]
        }
      ],
      "source": [
        "examplelabs = train_labels[:20]\n",
        "translabs = label_transform(examplelabs)\n",
        "exampletokens= train_tokens[:20]\n",
        "transtokens = text_transform(exampletokens)\n",
        "print(translabs)\n",
        "print(transtokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "VjeYaS-LN94A"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, texts, lengths):\n",
        "        embedded = self.embedding(texts)                          # VV note that lengths need to be on the CPU\n",
        "        embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        output, hidden = self.rnn(embedded)\n",
        "\n",
        "        return self.fc(hidden.squeeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "G2-gQiCLN94A"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(text_vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 4\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jGqWgMlN94A",
        "outputId": "d5493d5c-f8ae-4c20-c509-8dc96075ef65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 1,004,776 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VHyAMoBGN94A"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(DEVICE)\n",
        "criterion = criterion.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vkMQZqfZN94A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "\n",
        "    # Get the predictions for each class using softmax\n",
        "    softmax_preds = torch.softmax(preds, dim=1)\n",
        "\n",
        "    # Get the index of the highest probability class for each example\n",
        "    top_pred = torch.argmax(softmax_preds, dim=1)\n",
        "\n",
        "    # Check how many predictions match the true labels\n",
        "    correct = (top_pred == y).float()  # convert into float for division\n",
        "\n",
        "    # Calculate accuracy\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "CvZm7s1cN94A"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    for batch in tqdm(iterator, desc=\"\\tTraining\"):\n",
        "        optimizer.zero_grad()\n",
        "        labels, texts, lengths = batch\n",
        "        labels = labels.to(DEVICE).long()\n",
        "        predictions = model(texts, lengths)\n",
        "        predictions = predictions.to(DEVICE).float()\n",
        "        loss = criterion(predictions, labels)\n",
        "        acc = categorical_accuracy(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    print('finished batches')\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "fycQ6yuBxn4T"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_f1score(labels, predictions):\n",
        "  y_true = labels.numpy()\n",
        "  y_pred = labels.numpy()\n",
        "  score = f1_score(y_true, y_pred, average = 'weighted')\n",
        "  return score"
      ],
      "metadata": {
        "id": "uwNXRIYBx50t"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "4Xty9-YhN94B"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(iterator, desc=\"\\tEvaluation\"):\n",
        "            labels, texts, lengths = batch\n",
        "            labels = labels.to(DEVICE).long()\n",
        "            predictions = model(texts, lengths).squeeze(1)\n",
        "            predictions = predictions.to(DEVICE).float()\n",
        "            loss = criterion(predictions, labels)\n",
        "            acc = categorical_accuracy(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "            batch_predictions = predictions.argmax(dim=1)\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1EcCm6r-N94B"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xQnmSD4N94B",
        "outputId": "ab20558a-f07d-413a-8301-5665dbbc5caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU for training.\n",
            "Epoch: 01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTraining: 100%|██████████| 625/625 [00:02<00:00, 306.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished batches\n",
            "\tTrain Loss: 0.620 | Train Acc: 82.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tEvaluation: 100%|██████████| 78/78 [00:00<00:00, 892.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Val. Loss: 0.556 |  Val. Acc: 85.06%\n",
            "Epoch: 02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTraining: 100%|██████████| 625/625 [00:01<00:00, 349.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished batches\n",
            "\tTrain Loss: 0.601 | Train Acc: 82.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tEvaluation: 100%|██████████| 78/78 [00:00<00:00, 881.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Val. Loss: 0.539 |  Val. Acc: 85.26%\n",
            "Epoch: 03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTraining: 100%|██████████| 625/625 [00:01<00:00, 339.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished batches\n",
            "\tTrain Loss: 0.594 | Train Acc: 82.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tEvaluation: 100%|██████████| 78/78 [00:00<00:00, 900.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Val. Loss: 0.531 |  Val. Acc: 85.26%\n",
            "Epoch: 04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTraining: 100%|██████████| 625/625 [00:01<00:00, 341.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished batches\n",
            "\tTrain Loss: 0.590 | Train Acc: 82.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tEvaluation: 100%|██████████| 78/78 [00:00<00:00, 830.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Val. Loss: 0.530 |  Val. Acc: 85.24%\n",
            "Epoch: 05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTraining: 100%|██████████| 625/625 [00:01<00:00, 312.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished batches\n",
            "\tTrain Loss: 0.587 | Train Acc: 82.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tEvaluation: 100%|██████████| 78/78 [00:00<00:00, 668.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Val. Loss: 0.532 |  Val. Acc: 85.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "print(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'} for training.\")\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ahUSNYPN94B",
        "outputId": "9f296bdb-2f96-4ee8-ee79-480918bce020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tEvaluation: 100%|██████████| 78/78 [00:00<00:00, 831.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.520 | Test Acc: 85.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}