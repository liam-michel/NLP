{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHmWij42CnB5"
      },
      "source": [
        "\n",
        "\n",
        "# Experiment 1: Comparing BERT to ROBERTA model in both pre-trained and fine-tuned form\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTbcROZeRRbs"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G2TtnbcCoUp"
      },
      "outputs": [],
      "source": [
        "%pip install datasets\n",
        "%pip install transformers\n",
        "%pip install spacy\n",
        "%pip install spacy-transformers\n",
        "%pip install transformers[torch]\n",
        "%pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "DtIWGsoPnXOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiBzmBA_RTvB",
        "outputId": "21cc234a-f692-4ec7-d454-edbcf4a07acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  2.2.1+cu121\n",
            "torchtext Version:  0.17.1+cpu\n",
            "Using GPU.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "\n",
        "SEED = 1234\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"torchtext Version: \", torchtext.__version__)\n",
        "print(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3qO3j4uRUk0"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_oLf47NxRgQx"
      },
      "outputs": [],
      "source": [
        "def conv_label_indexes(training, valid, test ):\n",
        "\tlabel_encoding = {\"B-O\": 0, \"B-AC\": 1, \"B-LF\": 2, \"I-LF\": 3}\n",
        "\n",
        "\tlabel_list = []\n",
        "\tfor sample in training:\n",
        "\t\tlabel_list.append([label_encoding[tag] for tag in sample])\n",
        "\n",
        "\tval_label_list = []\n",
        "\tfor sample in valid:\n",
        "\t\tval_label_list.append([label_encoding[tag] for tag in sample])\n",
        "\n",
        "\ttest_label_list = []\n",
        "\tfor sample in test:\n",
        "\t\ttest_label_list.append([label_encoding[tag] for tag in sample])\n",
        "\treturn label_list, val_label_list, test_label_list\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Jr8sTDjiRmK9"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(dataset, tokenizer, label_list):\n",
        "    tokenized_inputs = tokenizer(dataset[\"tokens\"], truncation=True, is_split_into_words=True) ## For some models, you may need to set max_length to approximately 500.\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(label_list):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx])\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "89ZHh17tRnCq"
      },
      "outputs": [],
      "source": [
        "# BERT's tokenizer returns the dataset in the form of a dictionary of lists (sentences).\n",
        "# we have to convert it into a list of dictionaries for training.\n",
        "def turn_dict_to_list_of_dict(d):\n",
        "    new_list = []\n",
        "\n",
        "    for labels, inputs in zip(d[\"labels\"], d[\"input_ids\"]):\n",
        "        entry = {\"input_ids\": inputs, \"labels\": labels}\n",
        "        new_list.append(entry)\n",
        "\n",
        "    return new_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJQfj3rVRoXx",
        "outputId": "5e4fca77-72e0-4957-b445-ab93007777b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "metric = load_metric(\"seqeval\")\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "w-slJBbwRn2s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "label_encoding = {\"B-O\": 0, \"B-AC\": 1, \"B-LF\": 2, \"I-LF\": 3}\n",
        "inverse_label_map = {v: k for k, v in label_encoding.items()}\n",
        "\n",
        "def calculate_results(trainer, dataset):\n",
        "\n",
        "    predictions, labels, _ = trainer.predict(dataset)\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    textual_true_predictions = [\n",
        "        [inverse_label_map[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    textual_true_labels = [\n",
        "        [inverse_label_map[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=textual_true_predictions, references=textual_true_labels)\n",
        "\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxZCEVTWX1z9"
      },
      "source": [
        "# Load BERT model\n",
        "The first stage of this experiment is to view the performance of the BERT model in both its pre-trained and fine-tuned (transfer learning) form\\\n",
        "The BERT model uses the Encoder part of the transformer architecture, and its bidirectional nature makes it suitable for token classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQxcltLuYRb1",
        "outputId": "4cf172cd-e029-444d-c13d-260c202173a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70w1fp_VSibu"
      },
      "source": [
        "#Pre-process data (like in other experiments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Jh0FdivjeR3M"
      },
      "outputs": [],
      "source": [
        "training = dataset[\"train\"]\n",
        "valid = dataset[\"validation\"]\n",
        "test = dataset[\"test\"]\n",
        "\n",
        "training_labels = training[\"ner_tags\"]\n",
        "valid_labels = valid[\"ner_tags\"]\n",
        "test_labels = test[\"ner_tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Pjpwd5tQf-vu"
      },
      "outputs": [],
      "source": [
        "#convert label lists to indexes\n",
        "label_list, val_label_list, test_label_list = conv_label_indexes(training_labels, valid_labels, test_labels)\n",
        "\n",
        "\n",
        "tokenized_train = tokenize_and_align_labels(training, bert_tokenizer, label_list)\n",
        "tokenized_val_datasets = tokenize_and_align_labels(valid, bert_tokenizer, val_label_list)\n",
        "tokenized_test_datasets = tokenize_and_align_labels(test, bert_tokenizer, test_label_list)\n",
        "\n",
        "tokenized_train = turn_dict_to_list_of_dict(tokenized_train)\n",
        "tokenized_val = turn_dict_to_list_of_dict(tokenized_val_datasets)\n",
        "tokenized_test = turn_dict_to_list_of_dict(tokenized_test_datasets)\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(bert_tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZRuiNcQgeC2"
      },
      "source": [
        "# Setup trainer, don't train but use to run test set against pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNHmrLCEgdle",
        "outputId": "d90c0852-3daa-4181-931a-3cc7aae7d1bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "\n",
        "# Training arguments (feel free to play arround with these values)\n",
        "model_name = \"bert-base-uncased\"\n",
        "epochs = 6\n",
        "batch_size = 4\n",
        "learning_rate = 2e-5\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"BERT-finetuned-NER\",\n",
        "    # evaluation_strategy = \"epoch\", ## Instead of focusing on loss and accuracy, we will focus on the F1 score\n",
        "    evaluation_strategy ='steps',\n",
        "    eval_steps = 7000,\n",
        "    save_total_limit = 3,\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=0.001,\n",
        "    save_steps=35000,\n",
        "    metric_for_best_model = 'f1',\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    bert_model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator = data_collator,\n",
        "    tokenizer=bert_tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = calculate_results(trainer, tokenized_test)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "dUZbQRjNrzcl",
        "outputId": "532afb50-31fd-4485-c180-ade1748bce26"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 0, 0, 0, 2, 3, 3, 3, 3, 0, 1, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 3, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [1, 0, 2, 3, 3, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AC': {'precision': 0.09341368919500646,\n",
              "  'recall': 0.396709323583181,\n",
              "  'f1': 0.15121951219512197,\n",
              "  'number': 547},\n",
              " 'LF': {'precision': 0.018369175627240143,\n",
              "  'recall': 0.1357615894039735,\n",
              "  'f1': 0.03235990528808209,\n",
              "  'number': 302},\n",
              " 'O': {'precision': 0.8756046993780235,\n",
              "  'recall': 0.23476005188067445,\n",
              "  'f1': 0.37025131502045583,\n",
              "  'number': 5397},\n",
              " 'overall_precision': 0.25408197267577476,\n",
              " 'overall_recall': 0.24415626000640409,\n",
              " 'overall_f1': 0.24902024820378837,\n",
              " 'overall_accuracy': 0.25063900165388664}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7HQF3khiOWX"
      },
      "source": [
        "# Results of pre-trained BERT\n",
        "From the above f1 score of 40%, we can see that pre-trained BERT without fine tuning does not perform well for our token classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQQok5f4hPr_"
      },
      "source": [
        "# Fine tune BERT and run test set against it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "oKzQ7nWehPTb",
        "outputId": "77f49474-c00c-4867-c6fc-80696bf30aa7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1608' max='1608' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1608/1608 03:08, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1608, training_loss=0.16912953829883937, metrics={'train_runtime': 188.3494, 'train_samples_per_second': 34.149, 'train_steps_per_second': 8.537, 'total_flos': 278431018433184.0, 'train_loss': 0.16912953829883937, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = calculate_results(trainer, tokenized_test)\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "qBwkUwU6sIFF",
        "outputId": "98e1072b-a62a-425f-9acd-ca39767e20b8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 0, 0, 0, 2, 3, 3, 3, 3, 0, 1, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 3, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [1, 0, 2, 3, 3, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AC': {'precision': 0.7469458987783595,\n",
              "  'recall': 0.7824497257769653,\n",
              "  'f1': 0.7642857142857142,\n",
              "  'number': 547},\n",
              " 'LF': {'precision': 0.6897590361445783,\n",
              "  'recall': 0.7582781456953642,\n",
              "  'f1': 0.722397476340694,\n",
              "  'number': 302},\n",
              " 'O': {'precision': 0.9656853553347085,\n",
              "  'recall': 0.9542338336112656,\n",
              "  'f1': 0.9599254426840633,\n",
              "  'number': 5397},\n",
              " 'overall_precision': 0.9309073420968259,\n",
              " 'overall_recall': 0.9297150176112712,\n",
              " 'overall_f1': 0.9303107978212112,\n",
              " 'overall_accuracy': 0.9272289881220869}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6dgKknKidvq"
      },
      "source": [
        "# Roberta\n",
        "\n",
        "Above we can see that fine tuned BERT is much better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XmpQpvrVwqf"
      },
      "source": [
        "# Run test set against model before fine tuning\n",
        "We do this to gauge the performance of the models pre-trained state, i.e. testing how good it is for generalised use cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvP_9eJnV61L",
        "outputId": "2edbcd5d-a527-4fed-ac74-ac71625fb669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "# Load the RoBERTa tokenizer\n",
        "rob_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", add_prefix_space=True)\n",
        "\n",
        "# Load the RoBERTa model for token classification with the desired number of labels\n",
        "pretrained_rob_model = AutoModelForTokenClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vDn39j-bFbNK"
      },
      "outputs": [],
      "source": [
        "#tokenize training set\n",
        "label_list, val_label_list, test_label_list = conv_label_indexes(training_labels, valid_labels, test_labels)\n",
        "tokenized_train = tokenize_and_align_labels(training, rob_tokenizer, label_list)\n",
        "tokenized_val_datasets = tokenize_and_align_labels(valid, rob_tokenizer,  val_label_list)\n",
        "tokenized_test_datasets = tokenize_and_align_labels(test, rob_tokenizer, test_label_list)\n",
        "\n",
        "tokenized_train = turn_dict_to_list_of_dict(tokenized_train)\n",
        "tokenized_val = turn_dict_to_list_of_dict(tokenized_val_datasets)\n",
        "tokenized_test = turn_dict_to_list_of_dict(tokenized_test_datasets)\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(rob_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIPR6jO-jJqq"
      },
      "source": [
        "# Pre trained ROBERTA performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "ASUgyd6mXuQg",
        "outputId": "dd176d1c-26be-437b-862a-ce0185bf44e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 0, 0, 0, 2, 3, 3, 3, 3, 0, 1, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 3, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 0, 0, 0, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [1, 0, 2, 3, 3, 0] seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "\n",
        "# Training arguments (feel free to play arround with these values)\n",
        "model_name = \"roberta-base\"\n",
        "epochs = 6\n",
        "batch_size = 4\n",
        "learning_rate = 2e-5\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"ROBERTA-finedtuned-ner\",\n",
        "    # evaluation_strategy = \"epoch\", ## Instead of focusing on loss and accuracy, we will focus on the F1 score\n",
        "    evaluation_strategy ='steps',\n",
        "    eval_steps = 100,\n",
        "    save_total_limit = 3,\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=0.001,\n",
        "    save_steps=35000,\n",
        "    metric_for_best_model = 'f1',\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    pretrained_rob_model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator = data_collator,\n",
        "    tokenizer=rob_tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "pretrain_results = calculate_results(trainer, tokenized_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGs_uNIRYMr7",
        "outputId": "bc70f83b-d58e-452c-878b-942370f9dfdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'AC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 559},\n",
              " 'LF': {'precision': 0.04336043360433604,\n",
              "  'recall': 0.05517241379310345,\n",
              "  'f1': 0.048558421851289835,\n",
              "  'number': 290},\n",
              " 'O': {'precision': 0.807876882343207,\n",
              "  'recall': 0.925673113386424,\n",
              "  'f1': 0.8627728196518513,\n",
              "  'number': 5274},\n",
              " 'overall_precision': 0.7620974015870546,\n",
              " 'overall_recall': 0.7999346725461375,\n",
              " 'overall_f1': 0.7805577689243028,\n",
              " 'overall_accuracy': 0.7554531490015362}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrain_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RitJeao7xV9D"
      },
      "source": [
        "# Fine tune ROBERTA with training and look at result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "abQ9U6NzFbNL",
        "outputId": "8e983794-1612-416a-e630-10eecd9235fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1608' max='1608' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1608/1608 03:13, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.232008</td>\n",
              "      <td>0.573084</td>\n",
              "      <td>0.614136</td>\n",
              "      <td>0.592900</td>\n",
              "      <td>0.909663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.197183</td>\n",
              "      <td>0.619614</td>\n",
              "      <td>0.796562</td>\n",
              "      <td>0.697033</td>\n",
              "      <td>0.928549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.184607</td>\n",
              "      <td>0.685545</td>\n",
              "      <td>0.774594</td>\n",
              "      <td>0.727354</td>\n",
              "      <td>0.934057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.189672</td>\n",
              "      <td>0.729901</td>\n",
              "      <td>0.771729</td>\n",
              "      <td>0.750232</td>\n",
              "      <td>0.937834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.194144</td>\n",
              "      <td>0.719364</td>\n",
              "      <td>0.734479</td>\n",
              "      <td>0.726843</td>\n",
              "      <td>0.931539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.204416</td>\n",
              "      <td>0.709091</td>\n",
              "      <td>0.819484</td>\n",
              "      <td>0.760301</td>\n",
              "      <td>0.934372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.198121</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.819484</td>\n",
              "      <td>0.767785</td>\n",
              "      <td>0.939408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.220244</td>\n",
              "      <td>0.748815</td>\n",
              "      <td>0.754537</td>\n",
              "      <td>0.751665</td>\n",
              "      <td>0.935159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.252546</td>\n",
              "      <td>0.753861</td>\n",
              "      <td>0.745941</td>\n",
              "      <td>0.749880</td>\n",
              "      <td>0.932798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>0.200415</td>\n",
              "      <td>0.762072</td>\n",
              "      <td>0.829035</td>\n",
              "      <td>0.794145</td>\n",
              "      <td>0.942713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>0.222596</td>\n",
              "      <td>0.749546</td>\n",
              "      <td>0.788921</td>\n",
              "      <td>0.768730</td>\n",
              "      <td>0.936418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>0.241111</td>\n",
              "      <td>0.748828</td>\n",
              "      <td>0.763133</td>\n",
              "      <td>0.755913</td>\n",
              "      <td>0.932798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>0.235809</td>\n",
              "      <td>0.742194</td>\n",
              "      <td>0.794651</td>\n",
              "      <td>0.767528</td>\n",
              "      <td>0.937205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>0.236949</td>\n",
              "      <td>0.753400</td>\n",
              "      <td>0.793696</td>\n",
              "      <td>0.773023</td>\n",
              "      <td>0.939880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.091300</td>\n",
              "      <td>0.240238</td>\n",
              "      <td>0.754717</td>\n",
              "      <td>0.802292</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.938779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.091300</td>\n",
              "      <td>0.238961</td>\n",
              "      <td>0.753982</td>\n",
              "      <td>0.813754</td>\n",
              "      <td>0.782729</td>\n",
              "      <td>0.939408</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1608, training_loss=0.1671992943654606, metrics={'train_runtime': 193.7732, 'train_samples_per_second': 33.193, 'train_steps_per_second': 8.298, 'total_flos': 270367418028384.0, 'train_loss': 0.1671992943654606, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "y2RTZYNtFyOH",
        "outputId": "f7b89de3-5064-4af6-df1f-fdde785c6c67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AC': {'precision': 0.8464285714285714,\n",
              "  'recall': 0.8479427549194991,\n",
              "  'f1': 0.8471849865951743,\n",
              "  'number': 559},\n",
              " 'LF': {'precision': 0.7354838709677419,\n",
              "  'recall': 0.7862068965517242,\n",
              "  'f1': 0.76,\n",
              "  'number': 290},\n",
              " 'O': {'precision': 0.972259422230725,\n",
              "  'recall': 0.9635949943117179,\n",
              "  'f1': 0.9679078183030188,\n",
              "  'number': 5274},\n",
              " 'overall_precision': 0.948663277021486,\n",
              " 'overall_recall': 0.9446349828515433,\n",
              " 'overall_f1': 0.9466448445171849,\n",
              " 'overall_accuracy': 0.9419354838709677}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "results = calculate_results(trainer, tokenized_test)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I7Ew_XnzJVq"
      },
      "source": [
        "# Results of fine-tuned ROBERTA Model\n",
        "Performance of fine tuned roberta is very similar to that of the fine-tuned BERT model.\n",
        "\n",
        "\n",
        "*   BERT (fine tuned) F1 score: 0.9303741687364795\n",
        "*   ROBERTA (fine tuned) F1 score: 0.9421501147164864\n",
        "The difference is negligible, but Roberta is more computationally expensive to train / fine tune.\n",
        "It is worth noting that ROBERTA pre-trained out performs pre-trained BERT with an f1 score of\n",
        "\n",
        "\n",
        "*   BERT (pre-trained): 0.4012605042016807\n",
        "*   ROBERTA (pre-trained) 0.7805577689243028\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJQytfJf0Azp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}